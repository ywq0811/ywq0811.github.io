{"meta":{"title":"yanwq","subtitle":"blog","description":"yanwq blog","author":"yanwq","url":"https://www.yanwq.com","root":"/"},"pages":[{"title":"关于","date":"2024-03-18T12:01:58.701Z","updated":"2024-03-18T12:01:58.701Z","comments":false,"path":"about/index.html","permalink":"https://www.yanwq.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"404 Not Found：该页无法显示","date":"2024-03-18T12:01:58.661Z","updated":"2024-03-18T12:01:58.661Z","comments":false,"path":"/404.html","permalink":"https://www.yanwq.com/404.html","excerpt":"","text":""},{"title":"书单","date":"2024-03-18T12:01:58.701Z","updated":"2024-03-18T12:01:58.701Z","comments":false,"path":"books/index.html","permalink":"https://www.yanwq.com/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-03-18T12:01:58.758Z","updated":"2024-03-18T12:01:58.758Z","comments":true,"path":"links/index.html","permalink":"https://www.yanwq.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-03-18T12:01:58.768Z","updated":"2024-03-18T12:01:58.768Z","comments":false,"path":"tags/index.html","permalink":"https://www.yanwq.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2024-03-18T12:01:58.701Z","updated":"2024-03-18T12:01:58.701Z","comments":false,"path":"categories/index.html","permalink":"https://www.yanwq.com/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2024-03-18T12:01:58.768Z","updated":"2024-03-18T12:01:58.768Z","comments":false,"path":"repository/index.html","permalink":"https://www.yanwq.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"国产化鲲鹏系统安装ffmpeg","slug":"国产化麒麟安装ffmpeg","date":"2024-07-03T09:04:39.907Z","updated":"2024-07-03T09:08:37.291Z","comments":true,"path":"2024/07/03/国产化麒麟安装ffmpeg/","link":"","permalink":"https://www.yanwq.com/2024/07/03/%E5%9B%BD%E4%BA%A7%E5%8C%96%E9%BA%92%E9%BA%9F%E5%AE%89%E8%A3%85ffmpeg/","excerpt":"","text":"国产化鲲鹏系统安装ffmpeg 华为鲲鹏开源软件适配中心 1.搜索ffmpeg下载源码包 2.根据安装指导安装","categories":[{"name":"linux/arm64 鲲鹏","slug":"linux-arm64-鲲鹏","permalink":"https://www.yanwq.com/categories/linux-arm64-%E9%B2%B2%E9%B9%8F/"}],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://www.yanwq.com/tags/ffmpeg/"}]},{"title":"go通过gorm使用达梦数据库","slug":"go通过gorm使用达梦数据库","date":"2024-04-10T10:46:32.681Z","updated":"2024-04-10T10:53:28.974Z","comments":true,"path":"2024/04/10/go通过gorm使用达梦数据库/","link":"","permalink":"https://www.yanwq.com/2024/04/10/go%E9%80%9A%E8%BF%87gorm%E4%BD%BF%E7%94%A8%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"go通过gorm使用达梦数据库 根据官方文档说明，go想要通过gorm使用达梦数据库，需要下载orm方言包。 如图所示，达梦官方提供了2个版本的orm方言包 V1：github.com/jinzhu/gorm V2：gorm.io/gorm 本文档演示使用的是V2版本方言包 准备 dm 驱动包 + 依赖 v2方言包 go官方驱动地址：https://download.dameng.com/eco/adapter/resource/go/dm-go-driver.zip 下载好解压目录如下： dm-go-driver.zip // 驱动包 gorm_v1_dialect.zip // v1方言包 gorm_v2_dialect.zip // v2方言包 步骤 将 dm-go-driver.zip 解压之后，把 dm 包拷入到 GOPATH的src 目录下 【这个是dm驱动包】 在 src 目录下 终端下载依赖包 123go get github.com/golang/snappygo get golang.org/x/text/encoding 创建项目（演示的demo项目为 dm8-test） 将 gorm_v2_dialect.zip 解压之后，把dm 包拷入到dm8-test 项目 目录下（查看下面结构树）【这个是dm方言包】 此时，目录树如下 src ├── dm // 驱动包 ├── dm8-test // 演示demo │ ├── dm // 方言包 │ │ ├── create.go │ │ ├── dm.go │ │ ├── dm_test.go │ │ └── migrator.go │ ├── go.mod │ ├── go.sum │ └── main.go ├── github.com // 依赖包 └── golang.org // 依赖包 打开项目（演示的demo项目为 dm8-test）-&gt; go.mod -&gt; 新增replace dm =&gt; ../dm （指定dm包的来源路径） 连接 在 main.go 中测试连接 1234567891011121314151617package mainimport ( &quot;dm8-test/dm&quot; &quot;fmt&quot; &quot;gorm.io/gorm&quot;)func main() &#123; _, err := gorm.Open(dm.Open(&quot;dm://SYSDBA:SYSDBA@dm数据库IP:5236&quot;), &amp;gorm.Config&#123;&#125;) if err != nil &#123; panic(&quot;failed to connect database&quot;) &#125; fmt.Println(&quot;connect dm8 success!!&quot;)&#125; 其他 如果需要封装达梦数据库到组件中，可以把dm驱动包 和 dm方言包拷入对应组件中，记得需要删除dm驱动包中的 go.mod 和 .idea ，加到组件包的 go.mod中即可，同时还需要修改dm方言包中的引用dm驱动包的路径（除去GOPATH的实际路径即可）","categories":[{"name":"Go","slug":"Go","permalink":"https://www.yanwq.com/categories/Go/"}],"tags":[{"name":"达梦数据库","slug":"达梦数据库","permalink":"https://www.yanwq.com/tags/%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"gorm","slug":"gorm","permalink":"https://www.yanwq.com/tags/gorm/"}]},{"title":"uos-arm64 项目国产化部署","slug":"uos-arm64国产化","date":"2024-04-07T08:00:01.428Z","updated":"2024-04-07T08:10:58.840Z","comments":true,"path":"2024/04/07/uos-arm64国产化/","link":"","permalink":"https://www.yanwq.com/2024/04/07/uos-arm64%E5%9B%BD%E4%BA%A7%E5%8C%96/","excerpt":"","text":"国产化部署 说明：在 Uos 操作系统arm64架构服务器上实现项目国产化。 实现列表： 应用层 Sqlite 达梦数据库 应用层 可执行文件启动 说明：由于这个服务需要用到Sqlite，并且需要在linux/arm64服务器上执行。而我们的项目在windos环境下开发，就需要使用到交叉编译。由于安装了桌面版的ubuntu，可以通过linux环境访问到window路径。 安装 arm64 交叉编译工具链 1sudo apt-get install gcc-aarch64-linux-gnu 设置环境变量（设置环境变量以指示编译器和链接器使用arm64交叉编译工具链） 12export CC=aarch64-linux-gnu-gccexport CXX=aarch64-linux-gnu-g++ 通过linux环境进入到项目目录，交叉编译项目（以 unix-test 项目举例） 123cd unix-testGOOS=linux GOARCH=arm64 CGO_ENABLED=1 CC=aarch64-linux-gnu-gcc go build -v --ldflags=&quot;-X &#x27;google.golang.org/protobuf/reflect/protoregistry.conflictPolicy=warn&#x27;&quot; -o unix-test cmd/main.go 成功编译后，将可执行文件拷入 linx/arm64 服务器上 升级权限 1chmod +x unix-test 执行可执行文件 1./unix-test 可以看到使用的 Sqlite 数据库，连接成功，并且调用接口成功。 docker启动 在上面可执行文件基础上，使用arm64系统的基础镜像，进行docker部署 进入镜像仓库地址选择满足arm64版本的基础镜像 1https://hub.docker.com 在terminal(终端)上执行复制的命令(我使用的devel版本，可自行选择版本下载) 1docker pull arm64v8/ubuntu:devel 注：这里试过无数个 busybox 基础镜像版本，都不行；arm64v8/centos:latest 测试过也是可以的，但是被弃用了，所以就使用ubuntu了 将 Dockerfile 文件拷贝到服务器可执行文件 unix-test目录下， 修改FROM 1FROM arm64v8/ubuntu:devel 构建镜像（演示的项目为unix-test） 1docker build -t unix-test:1.0.0 . 执行docker run 命令启动服务 Sqlite 再windows环境下直接生成db文件即可。将db文件拷入 linux/arm64服务对应文件，读取即可。 再windows下进入Sqlite目录下 1Sqlite3 生成db文件（以 unix-test.db 为例） 1.open unix-test.db 再 sqlite 目录下会生成一个 unix-test.db 文件，拷入 linux/arm64 服务器对应位置 达梦数据库 需要下载使用arm64系统的镜像 在镜像仓库中找到满足的镜像 123https://hub.docker.com/r/qinchz/dm8-arm64我选择的是dm8 在terminal(终端)上执行复制的命令（镜像很大，下载很慢） 1docker pull qinchz/dm8-arm64 将基础镜像保存到本地 1docker save -o dm8-arm64.img qinchz/dm8-arm64:latest 将镜像拷入到arm64服务器 创建docker-compose.yml文件 vim docker-compose.yml 12345678910version: &#x27;3&#x27;services: DM8: image: qinchz/dm8-arm64:latest restart: always container_name: dm8 ports: - &quot;5236:5236&quot; volumes: - /home/test/kst/yanwq/md8/data:/home/dmdba/data 参数说明： version: '3'：指定使用的Docker Compose文件版本 services：定义服务的部分开始 DM8：定义服务的名称为DM8 image：指定使用的镜像为qinchz/dm8-arm64:latest restart: always：指定容器在退出时自动重启 container_name: dm8：指定创建的容器名称为dm8 ports：指定容器端口映射关系 5236:5236：将主机的5236端口映射到容器的5236端口 mem_limit: 1g：限制容器使用的内存为1GB memswap_limit: 1g：限制容器可以使用的swap交换空间为1GB volumes：指定挂载卷的配置 /home/test/kst/yanwq/md8/data:/home/dmdba/data：将主机的/home/test/kst/yanwq/md8/data目录挂载到容器的/home/dmdba/data目录，实现主机和容器之间的文件共享 启动服务 1docker-compose up -d 使用DBeaver运行达梦数据库","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.yanwq.com/categories/Linux/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.yanwq.com/tags/docker/"},{"name":"arm64","slug":"arm64","permalink":"https://www.yanwq.com/tags/arm64/"},{"name":"sqlite","slug":"sqlite","permalink":"https://www.yanwq.com/tags/sqlite/"},{"name":"达梦数据库","slug":"达梦数据库","permalink":"https://www.yanwq.com/tags/%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"RabbitMQ部署和使用文档","slug":"RabbitMQ部署","date":"2024-03-20T11:13:31.495Z","updated":"2024-03-20T11:19:03.615Z","comments":true,"path":"2024/03/20/RabbitMQ部署/","link":"","permalink":"https://www.yanwq.com/2024/03/20/RabbitMQ%E9%83%A8%E7%BD%B2/","excerpt":"","text":"RabbitMQ部署和使用文档 1.拉取镜像 1docker pull rabbitmq 2.启动服务 1docker run -d --restart always --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:latest 3.简单的go实现发送和接收消息代码 Sned.go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func main() &#123; // 1. 尝试连接RabbitMQ，建立连接 // 该连接抽象了套接字连接，并为我们处理协议版本协商和认证等。 conn, err := amqp.Dial(&quot;amqp://guest:guest@ip:port/&quot;) if err != nil &#123; fmt.Printf(&quot;connect to RabbitMQ failed, err:%v\\n&quot;, err) return &#125; defer conn.Close() // 2. 创建一个通道，大多数API都是用过该通道操作的。 ch, err := conn.Channel() if err != nil &#123; fmt.Printf(&quot;open a channel failed, err:%v\\n&quot;, err) return &#125; defer ch.Close() // 3. 声明消息要发送到的队列 q, err := ch.QueueDeclare( &quot;task_queue&quot;, // name false, // 持久的 false, // delete when unused false, // 独有的 false, // no-wait nil, // arguments ) if err != nil &#123; fmt.Printf(&quot;declare a queue failed, err:%v\\n&quot;, err) return &#125; // 4. 将消息发布到声明的队列 body := &quot;Hello World!&quot; //发送的消息 err = ch.Publish( &quot;&quot;, // exchange q.Name, // routing key false, // 立即 false, // 强制 amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, Body: []byte(body), &#125;) if err != nil &#123; fmt.Printf(&quot;publish a message failed, err:%v\\n&quot;, err) return &#125; log.Printf(&quot; [x] Sent %s&quot;, body)&#125; receive.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556func main() &#123; //1.建立连接 conn, err := amqp.Dial(&quot;amqp://guest:guest@ip:port/&quot;) if err != nil &#123; fmt.Printf(&quot;connect to RabbitMQ failed, err:%v\\n&quot;, err) return &#125; defer conn.Close() //2.获取channel ch, err := conn.Channel() if err != nil &#123; fmt.Printf(&quot;open a channel failed, err:%v\\n&quot;, err) return &#125; defer ch.Close() //3.声明队列 q, err := ch.QueueDeclare( &quot;task_queue&quot;, // name false, // 声明为持久队列 false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) if err != nil &#123; fmt.Printf(&quot;ch.Qos() failed, err:%v\\n&quot;, err) return &#125; //4.获取接收消息的delivery通道 msgs, err := ch.Consume( q.Name, // queue &quot;&quot;, // consumer true, // auto-ack, 如果是false,关闭自动消息确认 false, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil &#123; fmt.Printf(&quot;ch.Consume failed, err:%v\\n&quot;, err) return &#125; forever := make(chan bool) go func() &#123; for d := range msgs &#123; log.Printf(&quot;Received a message: %s&quot;, d.Body) &#125; &#125;() log.Printf(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;) &lt;-forever&#125;","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://www.yanwq.com/tags/rabbitMQ/"}]},{"title":"Linux执行mysql命令","slug":"linux执行mysql命令","date":"2024-03-20T11:13:25.510Z","updated":"2024-03-20T11:17:50.560Z","comments":true,"path":"2024/03/20/linux执行mysql命令/","link":"","permalink":"https://www.yanwq.com/2024/03/20/linux%E6%89%A7%E8%A1%8Cmysql%E5%91%BD%E4%BB%A4/","excerpt":"","text":"如果是dockers容器，需要先进入容器 1docker exec -it mysql sh 然后登陆mysql 12mysql -u root -p输入密码 显示数据库 1show databases; 打开数据库 123use 数据库名;例如:use kvpl; 显示表 1show tables; 显示表中记录 123select * from 表名;例如：select * from node; 建库 1create database 库名; 建表 1create table 表名; 删库 1drop database 库名; 删表 1drop table 表名; 删除表中所有记录 1delete from 表名;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.yanwq.com/categories/Linux/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.yanwq.com/tags/mysql/"}]},{"title":"go-zero的基本使用","slug":"go-zero使用文档","date":"2024-03-20T11:11:28.357Z","updated":"2024-03-20T11:17:50.575Z","comments":true,"path":"2024/03/20/go-zero使用文档/","link":"","permalink":"https://www.yanwq.com/2024/03/20/go-zero%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/","excerpt":"","text":"go-zero的基本使用 安装就不赘述了，照着官方文档即可，装好Goctl和protoc 1. 创建API工程 goctl 工具创建工程分为两种，一种是api工程，一种是rpc工程，如下： api：goctl api go -api user.api -dir . rpc：goctl rpc proto -src user.proto -dir . 其中，rpc工程的创建依赖.proto文件，而api工程的创建依赖.api文件 创建目录： 1mkdir go-zero-test 创建user接口工程的目录 1mkdir -p user/api &amp;&amp; cd user/api 用goland打开这个文件，创建go.mod 添加api文件 12345678910111213141516vim user.apitype ( HelloReq &#123; Name string `form:&quot;name&quot;` &#125; HelloRes &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` &#125;)service user-api &#123; @handler hello get /user/hello (HelloReq) returns (HelloRes)&#125; 创建api工程 1goctl api go -api user.api -dir . 可以看到生成了很多文件，文件结构看这里 2. 编写业务逻辑 user/api/internal/logic/hellologic.go 1234func (l *HelloLogic) Hello(req *types.HelloReq) (*types.HelloRes, error) &#123; msg := fmt.Sprintf(&quot;Hello %s&quot;, req.Name) return &amp;types.HelloRes&#123;Code: 0, Msg: msg&#125;, nil&#125; 进入api 1cd api 启动 1go run user.go 访问 http://localhost:8888/user/hello?name=hh 3. model层使用 可以归纳为以下步骤： 执行命令生成model文件 goctl model xxx config.go和yaml添加数据库和缓存的配置项 上下文中注入依赖 servicecontext.go 使用，从上下文中取出来用，l.svcCtx.XxxModel.Xxx() 另外，model层可以简便的切换为Gorm，但是api层就很难切换为Gin了。 3.1 model生成 在数据库中创建一张user表 在user目录下创建model目录 执行命令生成 1234cd user/modelgoctl model mysql datasource -url=&quot;root:123456@tcp(127.0.0.1:3306)/go-zero-test&quot; -table=&quot;user&quot; -c -dir .# 也可以用sql文件# goctl model mysql ddl -src user.sql -dir . -c 3.2 配置 添加mysql配置项 vim api/internal/config/config.go 12345678910111213package configimport &quot;github.com/tal-tech/go-zero/rest&quot;type Config struct &#123; rest.RestConf Mysql struct&#123; DataSource string &#125; CacheRedis cache.CacheConf&#125; 配置文件添加 vim api/etc/user-api.yaml 123456Mysql: DataSource: $user:$password@tcp($url)/$db?charset=utf8mb4&amp;parseTime=true&amp;loc=Asia%2FShanghaiCacheRedis: - Host: $host Pass: $pass Type: node 3.3 上下文注入model api/internal/svc/servicecontext.go 123456789101112type ServiceContext struct &#123; Config config.Config UserModel model.UserModel&#125;func NewServiceContext(c config.Config) *ServiceContext &#123; conn:=sqlx.NewMysql(c.Mysql.DataSource) return &amp;ServiceContext&#123; Config: c, UserModel: model.NewUserModel(conn,c.CacheRedis), &#125;&#125; 3.4 修改接口文件 user.api，添加登录接口 1234567891011121314151617181920212223242526272829303132syntax = &quot;v1&quot;type ( HelloReq &#123; Name string `form:&quot;name&quot;` &#125; HelloRes &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` &#125; LoginReq &#123; Username string `json:&quot;username&quot;` Password string `json:&quot;password&quot;` &#125; LoginReply &#123; Id int64 `json:&quot;id&quot;` Name string `json:&quot;name&quot;` Gender string `json:&quot;gender&quot;` AccessToken string `json:&quot;accessToken&quot;` AccessExpire int64 `json:&quot;accessExpire&quot;` RefreshAfter int64 `json:&quot;refreshAfter&quot;` &#125;)service user-api &#123; @handler login post /api/user/login (LoginReq) returns (LoginReply) @handler hello get /api/user/hello (HelloReq) returns (HelloRes)&#125; 再次执行goctl更新api 1goctl api go -api user.api -dir . 3.5 逻辑层使用model api/internal/logic/loginlogic.go 123456789101112131415161718192021222324func (l *LoginLogic) Login(req types.LoginReq) (*types.LoginReply, error) &#123; if len(strings.TrimSpace(req.Username)) == 0 || len(strings.TrimSpace(req.Password)) == 0 &#123; return nil, errors.New(&quot;参数错误&quot;) &#125; userInfo, err := l.svcCtx.UserModel.FindOneByName(req.Username) switch err &#123; case nil: case model.ErrNotFound: return nil, errors.New(&quot;用户名不存在&quot;) default: return nil, err &#125; if userInfo.Password != req.Password &#123; return nil, errors.New(&quot;用户密码不正确&quot;) &#125; return &amp;types.LoginReply&#123; Id: userInfo.Id, Name: userInfo.Username, Gender: strconv.FormatInt(userInfo.Gender, 10), &#125;, nil&#125; model自动生成的只有简单的增删改查，没有根据字段名的查询，这里可以自己实现FindOneByName函数 12345678910111213func (m *defaultUserModel) FindOneByName(username string) (*User, error) &#123; var resp User query := &quot;select * from user where username = ? limit 1;&quot; err := m.QueryRowNoCache(&amp;resp, query, username) switch err &#123; case nil: return &amp;resp, nil case sqlc.ErrNotFound: return nil, ErrNotFound default: return nil, err &#125;&#125; 4. jwt的使用 步骤归纳： config.go和yaml添加Auth配置项 编写token生成函数 需要鉴权的接口在api文件中添加jwt:Auth声明 重新执行命令生成api代码 5. 中间件 步骤归纳： api文件中添加middleware声明 重新执行命令生成api代码 上下文中注入依赖 编写中间件的Handle 处理逻辑 6. rpc服务 6.1 创建服务 编写proto文件 123456789101112131415161718192021vim user/rpc/user.protosyntax = &quot;proto3&quot;;package user;option go_package = &quot;user&quot;;message IdReq&#123; int64 id = 1;&#125;message UserInfoReply&#123; int64 id = 1; string name = 2; string gender = 3;&#125;service user &#123; rpc getUser(IdReq) returns(UserInfoReply);&#125; 生成rpc代码 12cd service/user/rpcgoctl rpc proto -src user.proto -dir . 如果使用了数据库和缓存记得修改config.go和yaml yaml添加etcd配置 1234Etcd: Hosts: - 127.0.0.1:2379 Key: user.rpc 如果调用了model层，记得在上下文中注入依赖（svc下servicecontext.go） 编写逻辑层 12345678910111213func (l *GetUserLogic) GetUser(in *user.IdReq) (*user.UserInfoReply, error) &#123; one, err := l.svcCtx.UserModel.FindOne(in.Id) if err != nil &#123; return nil, err &#125; return &amp;user.UserInfoReply&#123; Id: one.Id, Name: one.Name, Number: one.Number, Gender: one.Gender, &#125;, nil&#125; 调用rpc 6.2 调用服务 可以归纳为以下步骤： config.go和yaml添加rpc服务端的配置项 上下文中注入依赖 逻辑层可以从上下文中取出来调用 在调用端的config.go中加入rpc服务端的配置项 12345678type Config struct &#123; rest.RestConf Auth struct &#123; AccessSecret string AccessExpire int64 &#125; UserRpc zrpc.RpcClientConf &#125; yaml中添加rpc服务端的配置 12345UserRpc: Etcd: Hosts: - 127.0.0.1:2379 Key: user.rpc 上下文注入依赖(servicecontext.go) 12345678910111213type ServiceContext struct &#123; Config config.Config ... UserRpc userclient.User&#125;func NewServiceContext(c config.Config) *ServiceContext &#123; return &amp;ServiceContext&#123; Config: c, ... UserRpc: userclient.NewUser(zrpc.MustNewClient(c.UserRpc)), &#125;&#125; 逻辑层调用 123456789func (l *PingLogic) Ping() error &#123; fmt.Println(&quot;ping...&quot;) user, err := l.svcCtx.UserRpc.GetUser(l.ctx, &amp;userclient.IdReq&#123;Id: 3&#125;) fmt.Println(user, err) fmt.Println(&quot;api调用rpc咯&quot;) return nil&#125; 7. // 自适应降载保护 讲白了就是根据CPU压力来保护服务，压力过高时拒绝新的请求，直到当前积攒的请求处理完、CPU压力降下来后再次开放 但是目前我还测不出来，不知道是不是因为在windows上的原因，读取不到cpu使用率，从stat日志打出来的内容可以看到每次读取的cpu使用率都是0 在rest和zrpc框架里有可选激活配置 CpuThreshold，0-1000，默认值900，如果把值设置为大于0的值，则激活该服务的自动降载机制 如果请求被drop，那么错误日志里会有dropped关键字 官方文档 8. 熔断 在gprc调用中已经内置了，无需额外编码 熔断的算法看官方文档 测试起来比较简单 一个api接口、一个rpc接口，api接口调用rpc rpc接口内延时1秒，返回错误 连续请求api接口，会发现刚开始会等待1秒后才接收到响应，到后面已经是瞬间失败了，说明api接口没有再去调用rpc 9. 并发限制 RestConf中有有一个MaxConns配置用来限制并发数量 当程序中未处理完毕、未返回响应的请求数量超过此配置，后续请求将被直接拒绝 10. 引擎并发控制方案 - PeriodLimit 通过对zo-zero框架的了解，认为可以将其限流工具-PeriodLimit 作为引擎的并发控制方案之一 举个栗子，在3秒钟内，允许他10个并发 12345var ( seconds = 3 quota = 10 )l := limit.NewPeriodLimit(seconds, quota, redis.NewRedis(&quot;127.0.0.1:6379&quot;, redis.NodeType), &quot;periodlimit&quot;) do函数假设是调用引擎的处理函数，而这个函数执行完毕需要耗时3秒 123456789101112131415161718192021func do(l *limit.PeriodLimit, userID string, i int) &#123; // 通过 l.Take 传入的 key 来区分用户 code, err := l.Take(userID) if err != nil &#123; logx.Error(err) &#125; // 耗时3秒 time.Sleep(time.Second*3) switch code &#123; case limit.OverQuota: // 超出限制 logx.Errorf(&quot;OverQuota key: %v&quot;, i) case limit.Allowed: // 在限制范围内 logx.Infof(&quot;AllowedQuota key: %v&quot;, i) case limit.HitQuota: // 达到限制的临界点 logx.Errorf(&quot;HitQuota key: %v&quot;, i) default: logx.Errorf(&quot;DefaultQuota key: %v&quot;, i) &#125;&#125; 调用 123for i := 0; i &lt; 100; i++ &#123; go do(l, &quot;user1&quot;, i)&#125; 优点： 使用简单、开箱即用； 基于 redis 计数器，通过调用 redis lua script，保证计数过程的原子性，同时也支持分布式情况下正常计数； 缺点： 初始化时传入的时间限制与实际引擎调用的时间需要尽可能接近，否则会有误差； 要记录时间窗口内的所有行为记录，如果这个量特别大的时候，内存消耗会变得非常严重；","categories":[{"name":"Go","slug":"Go","permalink":"https://www.yanwq.com/categories/Go/"}],"tags":[{"name":"go-zero","slug":"go-zero","permalink":"https://www.yanwq.com/tags/go-zero/"}]},{"title":"163邮箱使用smtp服务发送消息","slug":"163邮箱使用smtp服务发送","date":"2024-03-20T11:11:24.477Z","updated":"2024-03-20T11:18:34.487Z","comments":true,"path":"2024/03/20/163邮箱使用smtp服务发送/","link":"","permalink":"https://www.yanwq.com/2024/03/20/163%E9%82%AE%E7%AE%B1%E4%BD%BF%E7%94%A8smtp%E6%9C%8D%E5%8A%A1%E5%8F%91%E9%80%81/","excerpt":"","text":"新创建的用户使用smtp服务发送email。会报错 1ERROR:User has no permission 原因是新注册的163邮箱默认是不开启客户端授权验证的（对自定的邮箱大师客户端默认开启） 因此登录总是会被拒绝，验证没有权限。解决办法是进入163邮箱，进入邮箱中心——客户端授权密码，选择开启即可，如下截图 设置完毕后，在代码中用使用客户端授权密码代替原始的邮箱密码，这样就可以正确的发送邮件了。 注：如果是很早之前就设置了，还是可以用登录密码，这个需要进入到163邮箱里查看，也可以升级成授权密码登录 163邮箱：yanwq0811@163.com 密码：*** 授权密码：BZWLUTMQGIYVOGIZ","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"consul","slug":"consul","permalink":"https://www.yanwq.com/tags/consul/"}]},{"title":"windows 安装node","slug":"windows安装node","date":"2024-03-20T09:04:36.714Z","updated":"2024-03-20T09:04:36.714Z","comments":true,"path":"2024/03/20/windows安装node/","link":"","permalink":"https://www.yanwq.com/2024/03/20/windows%E5%AE%89%E8%A3%85node/","excerpt":"","text":"windows 安装node 1.官网下载 https://nodejs.org/ 2.下载完成打开安装包，一直下一步安装完成 3.重启命令行，执行 node -v 查看是否安装成功","categories":[{"name":"Windows","slug":"Windows","permalink":"https://www.yanwq.com/categories/Windows/"}],"tags":[{"name":"node","slug":"node","permalink":"https://www.yanwq.com/tags/node/"}]},{"title":"windows10 安装和使用 ssh","slug":"windows安装ssh","date":"2024-03-20T09:04:36.714Z","updated":"2024-03-20T09:04:36.714Z","comments":true,"path":"2024/03/20/windows安装ssh/","link":"","permalink":"https://www.yanwq.com/2024/03/20/windows%E5%AE%89%E8%A3%85ssh/","excerpt":"","text":"windows10 安装和使用 ssh 安装 1.下载文件 下载地址：https://github.com/PowerShell/Win32-OpenSSH/releases 本人电脑64位 2.安装 将这个下载好的压缩包，解压到C:\\Program Files目录下 3.配置到系统环境变量中 4.进入到 C盘 -&gt; Users -&gt;对应的用户中 执行cmd运行ssh测试 生成SSH key cmd中执行命令生成密钥 1ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 出现这个图说明生成成功 2.进入C盘 -&gt; Users -&gt; 对应用户中查看,会生成一个 .ssh 文件夹 3.读取公钥并添加到github中 4.登录到 github.com 中 添加ssh key 5.对此从指定github上拉取项目就不需要验证了","categories":[{"name":"Windows","slug":"Windows","permalink":"https://www.yanwq.com/categories/Windows/"}],"tags":[{"name":"node","slug":"node","permalink":"https://www.yanwq.com/tags/node/"}]},{"title":"go-zero 生成和打包api和rpc","slug":"order打包","date":"2024-03-20T06:50:10.519Z","updated":"2024-03-20T07:03:09.197Z","comments":true,"path":"2024/03/20/order打包/","link":"","permalink":"https://www.yanwq.com/2024/03/20/order%E6%89%93%E5%8C%85/","excerpt":"","text":"api 1.goctl 生成order.api 1goctl api go -api order.api -dir . 2.构建 order-api 二进制 文件 123cd apiGOOS=linux GOARCH=amd64 go build -o order-api order.go 3.构建order-api镜像 1docker build -t order-api:1.4.0 . 4.保存镜像 1docker save -o order-api.img order-api:1.4.0 rpc 1.goctl生成order.porto 1goctl rpc protoc order.proto --go_out=./types --go-grpc_out=./types --zrpc_out=. 2.构建 order-rpc 二进制 文件 123cd rpcGOOS=linux GOARCH=amd64 go build -o order-rpc order.go 3.构建announcement-api镜像 1docker build -t order-rpc:1.4.0 . 4.保存镜像 1docker save -o order-rpc.img order-rpc:1.4.0","categories":[{"name":"Go","slug":"Go","permalink":"https://www.yanwq.com/categories/Go/"}],"tags":[{"name":"go-zero","slug":"go-zero","permalink":"https://www.yanwq.com/tags/go-zero/"}]},{"title":"wsl2-Ubuntu 安装 go","slug":"wsl2-ubuntu装go","date":"2024-03-20T06:49:47.684Z","updated":"2024-03-20T07:04:55.262Z","comments":true,"path":"2024/03/20/wsl2-ubuntu装go/","link":"","permalink":"https://www.yanwq.com/2024/03/20/wsl2-ubuntu%E8%A3%85go/","excerpt":"","text":"windows安装sqlite以及使用文档 1.重装ubuntu18.04 2.sudo su 进入root权限 cd /mnt/d/share 进入到d盘share文件夹下 cp go1.16.6.linux-amd64.tar.gz /usr/local/ 讲share文件夹下的go.tar拷贝到/usr/local 目录下 5.cd /usr/local 6.tar -xvf go.tar 解压go.tar文件 7.rm -rf go.tar 8.vim /etc/profile 添加： export GOROOT=/usr/local/go export GOPATH=/mnt/d/vagrant/data/gopath/src export GOPROXY=http://goproxy.cn export GOSUMDB=goproxy.cn export PATH=GOPATH/bin:GOPATH/bin:GOPATH/bin:GOROOT/bin:$PATH export SHARE=/mnt/d/share 9.source /etc/profile 10.go version","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.yanwq.com/categories/Ubuntu/"}],"tags":[{"name":"go","slug":"go","permalink":"https://www.yanwq.com/tags/go/"},{"name":"wsl2","slug":"wsl2","permalink":"https://www.yanwq.com/tags/wsl2/"}]},{"title":"docker 部署mysql","slug":"docker部署mysql5.7文档","date":"2024-03-20T06:49:21.020Z","updated":"2024-03-20T07:01:54.151Z","comments":true,"path":"2024/03/20/docker部署mysql5.7文档/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%E9%83%A8%E7%BD%B2mysql5.7%E6%96%87%E6%A1%A3/","excerpt":"","text":"docker 部署mysql 第1步：从Docker Hub拉取官方mysql镜像 docker pull mysql:5.7 第2步：使用docker images命令查看镜像 第3步：启动我们的mysql的镜像，创建一个MySQL容器 使用命令： 1docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 解释一下这里的参数： -d表示在后台运行，不随当前命令行窗口的退出而退出 –name给容器起一个别名，以后可以通过这个别名管理此容器 -p 3307：3307把宿主机的3307端口映射到Mysql容器的3306端口 -e MySQL容器的环境配置 第4步：查看我们已经启动的mysql容器 使用命令：docker ps 第5步：进入MySQl容器：使用的docker exec命令，-it是参数，bash表示创建一个交互界面 使用命令：docker exec -it mysql:5.7 /bin/bash 第6步：登录MySQL的服务器：使用的root用户登录的MySQL，在输入密码之后，我们可以看到已经进去了的MySQL mysql -u root -p 输入密码","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.yanwq.com/tags/mysql/"}]},{"title":"docker部署es数据库","slug":"docker部署es数据库","date":"2024-03-20T06:48:51.457Z","updated":"2024-03-20T07:09:27.473Z","comments":true,"path":"2024/03/20/docker部署es数据库/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%E9%83%A8%E7%BD%B2es%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"docker部署es数据库 1.获取镜像 1docker pull elasticsearch:7.14.0 2.创建相关文件夹 123mkdir -p /mnt/d/java/share/elasticsearch/configmkdir -p /mnt/d/java/share/elasticsearch/datamkdir -p /mnt/d/java/share/elasticsearch/plugins 3.配置文件 1echo &quot;http.host: 0.0.0.0&quot; &gt;&gt; /mnt/d/java/share/elasticsearch/config/elasticsearch.yml 配置完成，可以执行命令查看 1vim /mnt/d/java/share/elasticsearch/config/elasticsearch.yml 4.创建容器 1234567docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\&gt; -e &quot;discovery.type=single-node&quot; \\&gt; -e ES_JAVA_OPTS=&quot;-Xms84m -Xmx512m&quot; \\&gt; -v /mnt/d/java/share/elasticsearch/data:/usr/share/elasticsearch/data \\&gt; -v /mnt/d/java/share/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\&gt; -v /mnt/d/java/share/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\&gt; -d elasticsearch:7.14.0 5.测试正常移动页面 参考文档","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"es","slug":"es","permalink":"https://www.yanwq.com/tags/es/"}]},{"title":"docker consul 集群部署验证","slug":"docker consul 集群部署验证","date":"2024-03-20T06:48:46.201Z","updated":"2024-03-20T07:09:02.527Z","comments":true,"path":"2024/03/20/docker consul 集群部署验证/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%20consul%20%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E9%AA%8C%E8%AF%81/","excerpt":"","text":"docker consul 集群部署验证 主要记录 docker consul 集群部署完成之后验证的文档。 验证 1.查看成员（consul_server_1服务器） 1docker exec consul_server_1 consul members 2.查看集群的选举情况 1docker exec consul_server_1 consul operator raft list-peers 可以看到，目前的leader 是节点 consul_server_1 3.通过网页打开http://192.168.26.73:8500/ui看是否能看到consul看板 验证集群选举机制 1.重启leader（consul_server_1） 1docker restart consul_server_1 2.查看consul_server_2 和 consul_server_3 日志 consul_server_2: consul_server_3: 3.查看集群的选举情况 1docker exec consul_server_1 consul operator raft list-peers 通过步骤2和3，可以看到节点consul_server_2 被选举为新的 leader 注： 有一定几率，选举的leader 是重启后的节点（测试出现过，猜测是从日志上看重启的时候，其余正常的节点再尝试连接，返回了 connect:connection refused 报错，而且尝试连接不止一次，在尝试连接几次之后，发现连接不上，才开始选举，在选举的时候，重启完成了，可以参与选举，这里就不做深度研究，知道有几率出现这个情况即可） 验证节点优雅退出 1.consul_server_1 优雅退出 1docker exec consul_server_1 consul leave 优雅退出之后，查看服务状态是Exited 状态 2.查看节点状态 在其余节点服务器上执行，用的是consul_server_3 节点（根据实际情况查看） 1docker exec consul_server_3 consul members 3.查看leader 当前leader 节点是consul_server_2 （根据实际情况查看） 1docker exec consul_server_2 consul operator raft list-peers 查看后台日志，没有报错，访问ui正常，说明配置文件的bootstrap_expect=3，只是在创建集群的时候期待的节点数量，如果达不到就不会初次创建集群，但节点数据量达到3后，集群初次创建成功，后面如果server通过优雅退出，不影响集群的健康情况，集群仍然会正常运行，而优雅退出的集群的状态会标志为“left”。 4.重启优雅退出的节点（consul_server_1） 1docker restart consul_server_1 查看集群状态，发现consul_server_1 节点状态 还是left，尽管启动命令中加入了join 参数 （这个问题可以研究一下） 手动加入节点 再次查看集群状态 发现consul_server_1 节点的状态为 alive 节点自动加入集群 1.分别编辑sverer1、sverer2、sverer3 的配置文件，加入start_join 和 retry_join 字段 1vim config/config.json server2 和 server3 同样配置。 2.重新加载配置文件，验证配置是否正确 1docker exec consul_server_1 consul reload 我测试的consul_server_2 是 leader，加入了配置，但是没有重启leader。我重启的是 consul_server_1，测试优雅退出 consul_server_1，然后再重启，发现自动加入到了节点；也测试 consul_server_3 不加配置，然后优雅退出 consul_server_3 再重启，发现 consul_server_3 也自动加入到了节点。（这是为什么呢，从测试的结果来看，只要一个节点加入配置即可）","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"consul","slug":"consul","permalink":"https://www.yanwq.com/tags/consul/"}]},{"title":"docker consul 集群部署","slug":"docker consul 集群部署","date":"2024-03-20T06:48:44.857Z","updated":"2024-07-03T09:08:37.298Z","comments":true,"path":"2024/03/20/docker consul 集群部署/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%20consul%20%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"","text":"docker consul 集群部署 本文档演示的在一台服务器上部署节点=3的consul集群 准备 1.在宿主机上分别建立目录 server1 、server2 、server3 文件夹，并对应创建config 、data 、log 文件夹 其中： config ：配置文件路径。也是docker启动时读取的配置文件路径 data ：数据存储路径。docker启动时挂载到容器中的指定路径 log ：日志输出路径。（可以不落盘日志，本文档演示的是落盘日志） 单点部署 server1 1.进入到 config 目录下 1cd server1/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 1, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_1&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 参数说明： datacenter：指定consul的数据中心名称 bootstrap_expect：指定启动时需要的最少节点数 data_dir：指定consul在运行过程中存储数据的目录路径（容器内路径） log_file：指定consul输出的日志路径（容器内路径） log_level：指定consul日志输出的等级 node_name：指定consul的节点名称 client_addr：指定consul客户端访问地址 server：指定是否是server节点 ui：指定是否启用consul的web管理界面 enable_script_checks：指定是否启用支持脚本检查（Script Checks）功能。脚本检查允许用户通过自定义的脚本来检查服务的健康状态。 addresses：指定Consul agent监听的IP地址 log_file： 应该是 “/consul/log/” 3.配置启动命令 在server1 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d -p 8500:8500 --name=consul_server_1 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;eth0&#x27; consul agent -config-dir=/consul/config/config.json 参数说明 -d：在后台运行容器。 -p 8500:8500：指定容器内端口和宿主机端口的映射关系，将容器内的8500端口映射到宿主机的8500端口上。 --name=consul_server_1 ：指定容器名称为consul_server_1。 -v $PWD/data:/consul/data：挂载宿主机上的数据存储目录到容器中的/consul/data 目录 -v $PWD/config:/consul/config：挂载宿主机上的配置文件目录到容器中的/consul/config 目录 -v $PWD/log:/consul/log：挂载宿主机上的日志输出目录到容器中的/consul/log 目录 -e CONSUL_BIND_INTERFACE='eth0'：通过环境变量CONSUL_BIND_INTERFACE指定Consul绑定的网卡接口为eth0 consul agent ：启动consul agent -config-dir=/consul/config/config.json：指定配置文件路径（容器内），consul会自动读取配置文件中的参数 4.启动服务 1sh run.sh 5.通过网页打开http://127.0.0.1:8500/ui看是否能看到consul看板 加入ACL认证 1.使用linux的命令生成一个64位的UUID作为master token 1234uuidgenoutput:487d910a-a599-49b5-979e-57855e53b3b0 2.编写acl.hcl文件 1vim config/acl.hcl 12345678acl &#123; enabled = true default_policy = &quot;deny&quot; enable_token_persistence = true tokens &#123; master = &quot;487d910a-a599-49b5-979e-57855e53b3b0&quot; &#125;&#125; 3.重启服务 1docker restart consul_server_1 4.访问UI，提示需要输入token，输入上面配置的master token即可 集群部署 一台服务器部署 在一台服务器上部署consul集群，docker run命令可以使用-p 和 -e CONSUL_BIND_INTERFACE=‘eth0’ 的方式。因为在同一台服务器上，容器网卡是eth0。 server1 1.进入到 config 目录下 1cd server1/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_1&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 参数说明： datacenter：指定consul的数据中心名称 bootstrap_expect：指定启动时需要的最少节点数 data_dir：指定consul在运行过程中存储数据的目录路径（容器内路径） log_file：指定consul输出的日志路径（容器内路径） log_level：指定consul日志输出的等级 node_name：指定consul的节点名称 client_addr：指定consul客户端访问地址 server：指定是否是server节点 ui：指定是否启用consul的web管理界面 enable_script_checks：指定是否启用支持脚本检查（Script Checks）功能。脚本检查允许用户通过自定义的脚本来检查服务的健康状态。 addresses：指定Consul agent监听的IP地址 log_file： 应该是 “/consul/log/” 3.配置启动命令 在server1 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d -p 8500:8500 --name=consul_server_1 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;eth0&#x27; consul agent -config-dir=/consul/config/config.json 参数说明 -d：在后台运行容器。 -p 8500:8500：指定容器内端口和宿主机端口的映射关系，将容器内的8500端口映射到宿主机的8500端口上。 --name=consul_server_1 ：指定容器名称为consul_server_1。 -v $PWD/data:/consul/data：挂载宿主机上的数据存储目录到容器中的/consul/data 目录 -v $PWD/config:/consul/config：挂载宿主机上的配置文件目录到容器中的/consul/config 目录 -v $PWD/log:/consul/log：挂载宿主机上的日志输出目录到容器中的/consul/log 目录 -e CONSUL_BIND_INTERFACE='eth0'：通过环境变量CONSUL_BIND_INTERFACE指定Consul绑定的网卡接口为eth0 consul agent ：启动consul agent -config-dir=/consul/config/config.json：指定配置文件路径（容器内），consul会自动读取配置文件中的参数 4.启动服务 1sh run.sh 启动后，因为配置了bootstrap_expect=3，但只启动了一个server，所以会报错：没有集群领导者 需要把另外2个服务也启动起来！ server2 1.进入到 config 目录下 1cd server2/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_2&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 3.配置启动令 在server2 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d -p 8510:8500 --name=consul_server_2 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;eth0&#x27; consul agent -config-dir=/consul/config/config.json 4.启动服务 1sh run.sh 5.加入集群 1docker exec -it consul_server_3 consul join &#123;consul_server_1.IP&#125; server3 1.进入到 config 目录下 1cd server3/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_3&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 3.配置启动命令 在server3 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d -p 8520:8500 --name=consul_server_3 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;eth0&#x27; consul agent -config-dir=/consul/config/config.json 4.启动服务 1sh run.sh 5.加入集群 1docker exec -it consul_server_3 consul join &#123;consul_server_1.IP&#125; 加入ACL认证 1.生成UUID 1234uuidgenoutput: 2.分别在consul_server_1 、consul_server_2 、consul_server_3 的config 文件夹中新增acl.hcl 配置文件 1vim config/acl.hcl 123456789primary_datacenter = &quot;dc1&quot;acl &#123; enabled = true default_policy = &quot;deny&quot; enable_token_persistence = true tokens &#123; master = &quot;487d910a-a599-49b5-979e-57855e53b3b0&quot; &#125;&#125; 参数说明： enabled = true：代表开启ACL default_policy=“deny”：默认为allow，如果需要自定义权限，需要将其设置为deny enable_token_persistence =true： 开启token持久化，将token持久化到磁盘上 3.重启 consul_server_1 、 consul_server_2 、consul_server_3 服务 12345docker restart consul_server_1docker restart consul_server_2docker restart consul_server_3 5.启动UI界面查看，登录需要secreatID验证，即输入acl.hcl 配置文件中的master token 多台服务器部署 目前查找到能部署成功的方式是通过network的方式。 server1 服务器IP：192.168.26.73 1.进入到 config 目录下 1cd server1/config 2.创建 config.json 配置文件 1vim config.json ![image-20240226151703284](/imgs/2.png 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_1&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; log_file： 应该是 “/consul/log/” 3.配置启动命令 在server1 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d --net=host --name=consul_server_1 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;ens192&#x27; consul agent -bind=192.168.26.73 -config-dir=/consul/config/config.json 参数说明 -d：在后台运行容器。 --network=host：将容器连接到名为host的网络 --name=consul_server_1 ：指定容器名称为consul_server_1。 -v $PWD/data:/consul/data：挂载宿主机上的数据存储目录到容器中的/consul/data 目录 -v $PWD/config:/consul/config：挂载宿主机上的配置文件目录到容器中的/consul/config 目录 -v $PWD/log:/consul/log：挂载宿主机上的日志输出目录到容器中的/consul/log 目录 -e CONSUL_BIND_INTERFACE='ens192'：通过环境变量CONSUL_BIND_INTERFACE指定Consul绑定的网卡接口为ens192（这个根据实际的网卡名称，通过ifconfig 命令查看） consul agent ：启动consul agent -bind=192.168.26.73：指定Consul节点在Docker容器内监听的IP地址（服务器IP） -config-dir=/consul/config/config.json：指定配置文件路径（容器内），consul会自动读取配置文件中的参数 4.启动服务 1sh run.sh 启动后，因为配置了bootstrap_expect=3，但只启动了一个server，所以会报错：没有集群领导者 需要把另外2个服务也启动起来！ server2 服务器IP：192.168.26.74 1.进入到 config 目录下 1cd server2/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_2&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 3.配置启动命令 在server2 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d --network=host --name=consul_server_2 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;ens192&#x27; consul agent -bind=192.168.26.74 -join=192.168.26.73 参数说明 -join=192.168.26.73：将节点加入到consul_server_1 IP上 4.启动服务 1sh run.sh server3 服务器IP：192.168.26.75 1.进入到 config 目录下 1cd server3/config 2.创建 config.json 配置文件 1vim config.json 12345678910111213141516&#123; &quot;datacenter&quot;: &quot;dc1&quot;, &quot;bootstrap_expect&quot;: 3, &quot;data_dir&quot;: &quot;/consul/data&quot;, &quot;log_file&quot;: &quot;/consul/log/&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;node_name&quot;: &quot;consul_server_3&quot;, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;enable_script_checks&quot;: true, &quot;addresses&quot;: &#123; &quot;https&quot;: &quot;0.0.0.0&quot;, &quot;dns&quot;: &quot;0.0.0.0&quot; &#125;&#125; 3.配置启动命令 在server3 目录下 创建启动脚本run.sh 1mkdir run.sh 123#!/bin/bashdocker run -d --network=host --name=consul_server_3 -v $PWD/data:/consul/data -v $PWD/config:/consul/config -v $PWD/log:/consul/log -e CONSUL_BIND_INTERFACE=&#x27;ens192&#x27; consul agent -bind=192.168.26.75 -join=192.168.26.73 -config-dir=/consul/config/config.json 参数说明 -join=192.168.26.73：将节点加入到consul_server_1 IP上 4.启动服务 1sh run.sh 节点自动加入集群 1.分别编辑sverer1、sverer2、sverer3 的配置文件，加入start_join 和 retry_join 字段 1vim config/config.json server2 和 server3 同样配置。 2.重新加载配置文件，验证配置是否正确 1docker exec consul_server_1 consul reload 我测试的consul_server_2 是 leader，加入了配置，但是没有重启leader。我重启的是 consul_server_1，测试优雅退出 consul_server_1，然后再重启，发现自动加入到了节点；也测试 consul_server_3 不加配置，然后优雅退出 consul_server_3 再重启，发现 consul_server_3 也自动加入到了节点。（这是为什么呢，从测试的结果来看，只要一个节点加入配置即可） 加入ACL认证 方法一：配置acl.hcl ，通过consul acl bootstrap 生成token，然后把生成的token当做 master 的token。 本文档不采用该方法，有兴趣的可以自行去了解。参考文档 中【增加ACL token权限配置】目录。 方法二：使用linux的 uuidgen 命令生成一个64位UUID作为 master token，写入acl.hcl 配置文件中 1.生成UUID 1uuidgen output: 117b0d7f6-cd24-4989-ad84-9e1e5c938ce8 2.分别在consul_server_1 、 consul_server_2 、consul_server_3 的 config文件夹中 新增acl.hcl 配置文件，并将生成的token 加入文件中 1vim config/acl.hcl 123456789primary_datacenter = &quot;dc1&quot;acl &#123; enabled = true default_policy = &quot;deny&quot; enable_token_persistence = true tokens &#123; master = &quot;17b0d7f6-cd24-4989-ad84-9e1e5c938ce8&quot; &#125;&#125; 参数说明： enabled = true：代表开启ACL default_policy=“deny”：默认为allow，如果需要自定义权限，需要将其设置为deny enable_token_persistence =true： 开启token持久化，将token持久化到磁盘上 3.重启 consul_server_1 、 consul_server_2 、consul_server_3 服务 12345docker restart consul_server_1docker restart consul_server_2docker restart consul_server_3 4.启动UI界面查看 输入 acl.hcl 配置文件中的 master 的 token","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"consul","slug":"consul","permalink":"https://www.yanwq.com/tags/consul/"}]},{"title":"docker 部署grafana","slug":"docker部署grafana","date":"2024-03-20T06:48:19.942Z","updated":"2024-03-20T07:00:04.575Z","comments":true,"path":"2024/03/20/docker部署grafana/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%E9%83%A8%E7%BD%B2grafana/","excerpt":"","text":"docker 部署grafana 1.拉取镜像 1docker pull grafana/grafana:7.4.3 2.启动容器 1docker run -d --restart always -p 3000:3000 --name grafana grafana/grafana:7.4.3 3.网页访问，进入可视化界面 123部署服务器ip:3000输入用户名密码 admin/admin，进入会改密码","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"grafana","slug":"grafana","permalink":"https://www.yanwq.com/tags/grafana/"}]},{"title":"docker部署loki+promtail","slug":"docker 部署loki+promtail","date":"2024-03-20T06:48:17.932Z","updated":"2024-03-20T07:09:27.466Z","comments":true,"path":"2024/03/20/docker 部署loki+promtail/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%20%E9%83%A8%E7%BD%B2loki+promtail/","excerpt":"","text":"docker部署loki+promtail loki 1.拉取镜像 1docker pull grafana/loki:2.1.0 注：本文档适用2.1.0，不适合2.7.3版本，启动服务的时候会报wal错误 2.新建配置文件 12345678mkdir -p /home/loki #创建loki文件夹mkdir -p /home/loki/index #创建index文件夹 mkdir -p /home/loki/chunks #创建chunks文件夹chmod -R 777 /home/loki/index #提权chmod -R 777 /home/loki/chunks #提权cd /home/lokitouch loki-config.yaml //创建loki-config配置文件 3.打开配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455vim loki-config.yaml-----auth_enabled: false #是否启用身份验证，如果设置true。需要提供有效的用户名和密码才能访问lokiserver: http_listen_port: 3100 #定义loki实例监听的地址和端口 grpc_listen_port: 3110 #定义loki grpc监听的地址和端口 grpc_server_max_recv_msg_size: 1073741824 #grpc最大接收消息值，默认4m grpc_server_max_send_msg_size: 1073741824 #grpc最大发送消息值，默认4mingester: lifecycler: address: 127.0.0.1 ring: kvstore: store: inmemory replication_factor: 1 final_sleep: 0s chunk_idle_period: 5m chunk_retain_period: 30s max_transfer_retries: 0 max_chunk_age: 20m #一个timeseries块在内存中的最大持续时间。如果timeseries运行的时间超过此时间，则当前块将刷新到存储并创建一个新块schema_config: configs: - from: 2021-01-01 store: boltdb object_store: filesystem schema: v11 index: prefix: index_ period: 168hstorage_config: boltdb: directory: /home/loki/index #存储索引地址 filesystem: directory: /home/loki/chunkslimits_config: enforce_metric_name: false reject_old_samples: true reject_old_samples_max_age: 168h ingestion_rate_mb: 30 #修改每用户摄入速率限制，即每秒样本量，默认值为4M ingestion_burst_size_mb: 15 #修改每用户摄入速率限制，即每秒样本量，默认值为6Mchunk_store_config: #max_look_back_period: 168h #回看日志行的最大时间，只适用于即时日志 max_look_back_period: 0stable_manager: retention_deletes_enabled: false #日志保留周期开关，默认为false retention_period: 0s #日志保留周期 4.启动容器 123docker run -d --restart always -p 3100:3100 --privileged=true --name loki -v /home/loki:/mnt/config -v /home/loki/index:/opt/loki/index -v /home/loki/chunks:/opt/loki/chunks grafana/loki:2.0.1 -config.file=/mnt/config/loki-config.yaml复用修改宿主机挂载的路径即可 5.验证 1234curl http://127.0.0.1:3100/api/prom/labelcurl localhost:3100/loki/api/v1/labels注：第一个curl如果返回&#123;&#125;或者空，则失败，查看配置文件或者查看日志排查原因 promtail 123promtail 是日志收集器，用于将日志发送到loki进行存储和分析。promtail 可以以代理的方式运行在应用程序所在的主机上，通过监控日志文件或者通过日志文件的标准输出来收集日志信息。Promtail将收集到的日志数据结构化为Loki所需的格式，并将其发送到Loki实例中。Loki则负责对日志进行存储，并提供查询和浏览日志的功能。 根据上面的定义，promtail一般部署在应用程序所在服务器上。此文档拿tts-svc-dev应用程序来当例子，收集tts-svc-dev的日志发送给loki。所以promtail部署在tts-svc-dev服务器上（192.168.26.74:3200） 1.拉取镜像 1docker pull grafana/promtail:2.1.0 2.创建文件夹 123mkdir -p /home/kst/aihc/promtailcd /home/kst/aihc/promtailtouch promtail-config.yaml 3.打开配置文件 123456789101112131415161718192021222324vim promtail-config.yaml------server: http_listen_port: 9080 #云服务器需开放9080端口 grpc_listen_port: 0positions: filename: /tmp/positions.yaml#把loki当客户端连接clients: - url: http://192.168.2.50:3100/loki/api/v1/push #这里修改实际loki的ip：portscrape_configs: - job_name: tts-svc-dev #标签，用于查询 #pipeline_stages: static_configs: - targets: - localhost labels: #标签，用于后面的查询 job: tts-svc-dev __path__: /var/log/tts-svc-dev/*.log #注意，这里的路径是映射主机的/data/aihc/tts-svc/dev/log目录的容器里的目录，指的是容器里面映射的路径 4.启动容器 123docker run -d --name promtail --privileged=true -p 9080:9080 -m 1024m -v /home/kst/aihc/promtail:/mnt/config -v /data/aihc/tts-svc/dev/log:/var/log/tts-svc-dev/ -v /etc/localtime:/etc/localtime:ro grafana/promtail:2.1.0 -config.file=/mnt/config/promtail-config.yaml注： 这里需要把宿主机tts-svc日志存储路径挂载进容器里面， 对应配置文件的_path_参数 5.验证 1curl &quot;http://192.168.2.50:3100/api/prom/label&quot; #实际loki的ip:port 6.接下来就可以访问grafana查看了 grafana界面配置 1.打开grafana访问路径,此文档部署grafana路径是192.168.2.50:3100 123网页打开 http://192.168.2.50:3100初始化账户和密码为:admin admin登录之后会跳出修改密码界面，点击【spik】可以跳过 2.添加loki 然后拉到下面，点击【Save &amp; Test】，即添加成功 3.使用loki 可以看到有我们刚才配置的Job_name，点击【tts-svc-dev】 成功查看日志 4.操作日志 可以点击【Add query】，输入需要查询的，查出指定日志。查询方式可百度","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"grafana","slug":"grafana","permalink":"https://www.yanwq.com/tags/grafana/"}]},{"title":"docker 操作oracle数据库文档","slug":"docker操作oracle导入导流程","date":"2024-03-20T06:47:51.533Z","updated":"2024-03-20T06:59:13.832Z","comments":true,"path":"2024/03/20/docker操作oracle导入导流程/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%E6%93%8D%E4%BD%9Coracle%E5%AF%BC%E5%85%A5%E5%AF%BC%E6%B5%81%E7%A8%8B/","excerpt":"","text":"docker 操作oracle数据库文档 说明：本文档主要是记录docker部署oracle，操作数据库文档，docker 部署oracle可以参考docker部署oracle docker部署完oracle数据库后 1.通过指令来查看oarcle进程名 1docker ps 2.找到oracle进程服务，通过指令进入oracle容器 1docker exec -it 进程名 bash 3.切换root用户，输入密码 123su root再跳出Password：时，输入密码：helowin 4.切换oracle用户，无需输入密码 , 1su - oracle 或者3.不执行， 直接执行4，输入密码进入 12su - oraclePassword: oracle 5.登录sqlplus软连接 1sqlplus /nolog 6.显示当前用户 1234show user;结果为：USER is &quot;&quot; //说明当前没有登录用户 7.切换用户 【如果没有创建用户，可以参考下面三.创建用户流程,以用户 yanwq为例。 部署oracle完，oracle内部有2个建好的用户：system和sys, 用户可直接登录到system用户以创建其他用户，因为system具有创建别 的用户的 权限。 在安装oracle时，用户或系统管理员首先可以为自己建立一个用户。】 1234conn yanwq/123456结果为：Connected. //用户连接成功 8.输入sql语句，查看表数据，这边以voice表为例 1select * from voice; 9.directories是oracle类似虚拟目录的一个概念，它对应服务器上的一个具体路径。可以使用命令查看现有的directory也可以直接创建新的，建议创建新的，比较简单 123456789101112/查询现有的directoryselect * from dba_directories;/创建一个新的directoriescreate or replace directory yanwq_bak as &#x27;/home/oracle/app&#x27;结果为：Directory created.说明：创建一个directories =yanwq_bak的在/home/oracle/app下 ，可以修改路径和yanwq_bak 9.退出 1exit 10.执行命令导出数据和日志 123expdp yanwq/123456 directory=yanwq_bak dumpfile=yanwq.dmp logfile=yanwq.log说明:使用yanwq用户连接数据库，并导出yanwq用户的数据，这样就会将dmp和log文件存放在服务器上的/home/oracle/app目录下 11.执行一下命令进入app目录下，验证是否有生成yanwq.dmp和yanwq.log文件 1cd /home/oracle/app 12.导入数据, 导入之前建议先将表删除，因为oracle数据是归属于用户的，所以我们一般是先将用户删除掉之后，重建，再执行impdp命令进行导入数据。 【进过测试只清理掉表数据，无法导入，会提示tableName exists.会跳过导入这个表的操作，删除表是可以导入的】 1impdp yanwq/123456 directory=yanwq_bak dumpfile=yanwq.dmp logfile=yanwq.log 其他： 一、创建用户 oracle内部有两个建好的用户：system和sys。用户可直接登录到system用户以创建其他用户，因为system具有创建别 的用户的 权限。 在安装oracle时，用户或系统管理员首先可以为自己建立一个用户。 语法[创建用户]： create user 用户名 identified by 口令[即密码]； 例子： create user test identified by test; 语法[更改用户]: alter user 用户名 identified by 口令[改变的口令]; 例子： alter user test identified by 123456; 二、删除用户 语法：drop user 用户名; 例子：drop user test; 若用户拥有对象，则不能直接删除，否则将返回一个错误值。指定关键字cascade,可删除用户所有的对象，然后再删除用户。 语法： drop user 用户名 cascade; 例子： drop user test cascade; 三.创建用户流程,以用户 yanwq为例 进入容器之后，进入Oracle：sqlplus /nolog 使用sysdba登录oracle：conn sys/oracle as sysdba 创建用户：create user yanwq identified by 123456 赋予用户权限：grant dba to yanwq 登录：grant create session to yanwq conn yanwq /123456 四.删除表数据 TRUNCATE TABLE voice;","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://www.yanwq.com/tags/oracle/"}]},{"title":"docker日志过大清理文档","slug":"docker日志过大清理问题","date":"2024-03-20T06:47:43.413Z","updated":"2024-03-20T06:59:13.822Z","comments":true,"path":"2024/03/20/docker日志过大清理问题/","link":"","permalink":"https://www.yanwq.com/2024/03/20/docker%E6%97%A5%E5%BF%97%E8%BF%87%E5%A4%A7%E6%B8%85%E7%90%86%E9%97%AE%E9%A2%98/","excerpt":"","text":"docker日志过大清理文档 背景：docker服务使用时间久，docker会一直堆积日志。导致磁盘空间过小，这时候就需要清理服务日志。 方案一： 此方案没有测试过，建议使用方案2，方案2，测试过，没有问题 可能由于docker部署的时候，挂载根目录，而根目录磁盘空间不是很大，在日积月累的情况下，会出现docker 日志文件过大，从而导致磁盘空间不足。这时间就需要清理日志。 此方案就是通过配置docker 日志大小，来解决。例如：/var/lib/docker/containers/xxx/xxx-json.log 文件过大了 解决： 1234567891011121314151617181920212223242526272829在/var/lib/docker/containers目录下的Docker容器日志文件的大小是由Docker守护进程中的日志驱动程序配置决定的。默认情况下，Docker使用的是json-file日志驱动程序。要配置这些日志文件的大小，可以在Docker守护进程的配置文件/etc/docker/daemon.json中添加日志驱动程序参数。以下是一种配置日志文件大小的方法：打开Docker守护进程的配置文件/etc/docker/daemon.json（如果文件不存在，则创建它）。在该文件中添加以下配置：&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;3&quot; &#125;&#125;这里使用的是json-file日志驱动程序，它将日志保存为JSON格式文件。max-size参数用于指定每个日志文件的最大大小，单位可以是B（字节），k（千字节），m（兆字节）或g（吉字节）。max-file参数用于指定保存的日志文件数量。在这个示例中，每个日志文件的最大大小为10兆字节（10m），系统会自动轮转日志，并保留最多3个日志文件。保存并关闭文件。重启Docker守护进程，以使配置生效。可以使用以下命令重启Docker守护进程：sudo systemctl restart docker现在，/var/lib/docker/containers目录下的Docker容器日志文件的大小已经被配置为每个文件最大为10兆字节，最多保留3个文件。请注意，这对于新的容器会生效，对于已经运行的容器需要进行其他操作以使其生效。 方案二 通过清空docker 日志来达到效果 解决： 12345678910111213141516171819直接删除/var/lib/docker/containers目录下的日志文件可能会对正在运行的容器或已启动的服务产生不可预测的影响，因为容器的运行依赖于这些日志文件。虽然删除日志文件不会直接影响容器的运行，但会导致你无法查看容器的日志记录。如果你想删除这些日志文件，最好的做法是使用Docker提供的日志管理工具来处理：使用以下命令列出正在运行的容器：docker ps记录你要处理的容器的容器ID。使用以下命令来获取指定容器的日志文件路径：docker inspect --format=&#x27;&#123;&#123;.LogPath&#125;&#125;&#x27; &lt;容器ID&gt;替换&lt;容器ID&gt;为你要处理的容器的真实ID。使用命令echo &quot;&quot; &gt; &lt;日志文件路径&gt;清空该日志文件，而不是直接删除它。例如：echo &quot;&quot; &gt; /var/lib/docker/containers/&lt;容器ID&gt;/&lt;容器ID&gt;-json.log替换&lt;日志文件路径&gt;为第2步中获取的日志文件路径。这样，你就将日志文件清空了，而不会删除它们。容器将继续将日志写入这些文件，但现有的日志将被清空。请注意，如果你删除了整个/var/lib/docker/containers目录，将会丢失所有容器的配置和数据，包括正在运行的容器。如果需要删除整个目录，最好通过停止和删除容器后删除整个目录，并确保有备份所有重要的容器配置和数据。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.yanwq.com/tags/docker/"}]},{"title":"linux自带定时器操作文档","slug":"linux自带定时器操作文档","date":"2024-03-20T06:47:31.414Z","updated":"2024-03-20T07:11:52.360Z","comments":true,"path":"2024/03/20/linux自带定时器操作文档/","link":"","permalink":"https://www.yanwq.com/2024/03/20/linux%E8%87%AA%E5%B8%A6%E5%AE%9A%E6%97%B6%E5%99%A8%E6%93%8D%E4%BD%9C%E6%96%87%E6%A1%A3/","excerpt":"","text":"linux自带定时器操作文档 计划任务是需要在指定时间执行的任务或者是周期性执行的任务，比如凌晨3点重启设备，每周对日志文件备份等。Linux系统会内置at和cron服务，at服务用来在指定时间执行任务，cron用来周期性执行任务。 一.at一次性任务 参考连接 二.cron周期性任务 1、cron周期性任务依赖于系统后台的crond进程，类似于at，我们也要首先确认cron服务是否开启，执行命令： 1systemctl status crond 2、启动crontab服务 一般启动服务用 /sbin/service crond start 若是根用户的cron服务可以用 sudo service crond start， 这里还是要注意 下 不同版本linux系统启动的服务的命令也不同 ，像我的虚拟机里只需用 sudo service cron restart 即可，若是在根用下直接键入service cron start就能启动服务 3、查看服务是否已经运行用 ps -ax | grep cron cron.daily是每天执行一次的job cron.weekly是每个星期执行一次的job cron.monthly是每月执行一次的job cron.hourly是每个小时执行一次的job cron.d是系统自动定期需要做的任务 crontab是设定定时任务执行文件 cron.deny文件就是用于控制不让哪些用户使用Crontab的功能 4.用户配置文件： 每个用户都有自己的cron配置文件,通过crontab -e 就可以编辑,一般情况下我们编辑好用户的cron配置文件保存退出后,系统会自动就存放于/var/spool/cron/目录中,文件以用户名命名.linux的cron服务是每隔一分钟去读取一次/var/spool/cron,/etc/crontab,/etc/cron.d下面所有的内容. 5.crontab文件格式： * * * * command minute hour day month week command 分 时 天 月 星期 命令 minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 6、crontab命令 cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明: crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数 crontab -l //列出某个用户cron服务的详细内容 crontab -r //删除没个用户的cron服务 crontab -e //编辑某个用户的cron服务 比如说root查看自己的cron设置:crontab -u root -l 再例如，root想删除fred的cron设置:crontab -u fred -r 示例 当前是root用户 1.创建一个root用户底下的定时任务 1crontab -u root -e 如下是编辑器内容 1230 2 * */6 * /home/yanwq/kvp-cmsb/cleanlog注释：每隔6个月的2点执行cleanlog脚本 操作成功图: 2.查看root用户底下的定时任务 1crontab -u root -l 操作成功图: 如果刚创建完定时任务，执行crontab -u root -l没有结果，需要重新加载cron服务，每个linux系统启动的服务命令是不一样 1/sbin/service crond reload","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.yanwq.com/categories/Linux/"}],"tags":[{"name":"cron","slug":"cron","permalink":"https://www.yanwq.com/tags/cron/"}]},{"title":"解决http.Get()方法请求https 证书报错问题","slug":"解决http.Get 请求https证书报错问题","date":"2024-03-20T06:47:14.685Z","updated":"2024-03-20T07:09:27.458Z","comments":true,"path":"2024/03/20/解决http.Get 请求https证书报错问题/","link":"","permalink":"https://www.yanwq.com/2024/03/20/%E8%A7%A3%E5%86%B3http.Get%20%E8%AF%B7%E6%B1%82https%E8%AF%81%E4%B9%A6%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/","excerpt":"","text":"解决http.Get()方法请求https 证书报错问题 123resp,err := http.Get(&quot;https://XXX&quot;)报错：x509: certificate signed by unknown authority 原因：http.Get()会对传过来的数字证书进行校验，但是这个证书是由不知名CA签发的 解决方法： 修改client.go代码。让client端忽略对证书的校验： 1234567//通过设置tls.Config的InsecureSkipVerify为true，client将不再对服务端的证书进行校验。tr := &amp;http.Transport&#123; TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: true&#125;, &#125; client := &amp;http.Client&#123;Transport: tr&#125; resp, err := client.Get(&quot;https://localhost:8081&quot;) 这种做法可以解决问题，但是可能在生产环境下不进行校验，可能存在风险 将CA证书放在项目代码下，加入到dockerfile里 每台ubunt上都有CA证书，在目录/etc/ssl/certs下，都有ca-certificates.crt这个就是证书，将他拷贝到项目代码下，以asr-svc为例 然后再dockerfile加入证书 12WORKDIR /etc/ssl/certsADD ca-certificates.crt . 即可，打包镜像，运行代码。 参考文档","categories":[{"name":"Go","slug":"Go","permalink":"https://www.yanwq.com/categories/Go/"}],"tags":[{"name":"https","slug":"https","permalink":"https://www.yanwq.com/tags/https/"}]},{"title":"重装 windows ubuntu","slug":"重装windows ubunut","date":"2024-03-20T06:47:12.699Z","updated":"2024-03-20T07:06:23.680Z","comments":true,"path":"2024/03/20/重装windows ubunut/","link":"","permalink":"https://www.yanwq.com/2024/03/20/%E9%87%8D%E8%A3%85windows%20ubunut/","excerpt":"","text":"重装 windows ubuntu 1.https://www.yuque.com/shaycormac/blog/tn88q0 根据这个文档安装wls2和docker destop 2.windows商店下载terminal 3.配置/etc/profile 4.保存配置 source profile 5.下载go 6.更新源 https://www.cnblogs.com/ssxblog/p/11357126.html 7.安装mingw 1apt install gcc 8.开始编译二进制文件（刚从gitlub clone下来需要go mod tidy） 9使用make image命令需要先安装apt install make 和 apt install make-guile ,可以按要求直接安装. 10.需要加载基础镜像kvp-centos-ffmpeg-minial.img (在/d/java/share里面),然后执行docker load -i kvp-centos-ffmpeg-minial.img","categories":[{"name":"Windows","slug":"Windows","permalink":"https://www.yanwq.com/categories/Windows/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://www.yanwq.com/tags/ubuntu/"}]},{"title":"proto生成go文件指令","slug":"proto生成go文件指令","date":"2024-03-20T06:37:22.181Z","updated":"2024-03-20T06:45:47.159Z","comments":true,"path":"2024/03/20/proto生成go文件指令/","link":"","permalink":"https://www.yanwq.com/2024/03/20/proto%E7%94%9F%E6%88%90go%E6%96%87%E4%BB%B6%E6%8C%87%E4%BB%A4/","excerpt":"","text":"proto生成go文件指令 在当前目录下生成xxx.proto的pb文件 123protoc --go_out ./ ./xxx.proto或protoc --go_out=. --go-grpc_out=. kvps_forward.proto 或者 1protoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative wenet.20230301.proto","categories":[{"name":"Proto","slug":"Proto","permalink":"https://www.yanwq.com/categories/Proto/"}],"tags":[{"name":"proto","slug":"proto","permalink":"https://www.yanwq.com/tags/proto/"}]},{"title":"windows安装sqlite以及使用文档","slug":"windows安装sqlite以及使用","date":"2024-03-20T06:37:11.621Z","updated":"2024-03-20T06:43:59.736Z","comments":true,"path":"2024/03/20/windows安装sqlite以及使用/","link":"","permalink":"https://www.yanwq.com/2024/03/20/windows%E5%AE%89%E8%A3%85sqlite%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8/","excerpt":"","text":"windows安装sqlite以及使用文档 安装 1.进入官网安装包下载路径:https://www.sqlite.org/download.html 选择windows版本下载 2.选择路径加入下载的文件，我的路径D:\\java\\sqlite（或者C:\\sqlite下） 3.将下载解压出来的5个文件，拷贝到D:\\java\\sqlite 4.将D:\\java\\sqlite加入到环境变量 5.打开cmd，输入’sqlite3’，将显示SQLite版本即表示安装成功 提示：红色字体表示目前未指定相关数据库文件，而是以内存作为数据表等的存储位置 使用 sqlite没用管理界面，只能在命令行中进行crud。（或者自行安装可视化管理界面） 以下操作都需要在环境变量路径下执行cmd，再执行sqlite3后执行 1.创建数据库，创建的数据库存储在sqlite3.exe所在的文件夹 1.open test.db //test.db 就是创建的数据库 效果图： 2.查看数据库 1.databases 效果图 （我这里是删除了test.db 数据库，重新建了一个kfa-workstation.db 数据库） [其他参考][https://www.likecs.com/show-205144414.html]","categories":[{"name":"DB","slug":"DB","permalink":"https://www.yanwq.com/categories/DB/"}],"tags":[{"name":"db","slug":"db","permalink":"https://www.yanwq.com/tags/db/"}]}],"categories":[{"name":"linux/arm64 鲲鹏","slug":"linux-arm64-鲲鹏","permalink":"https://www.yanwq.com/categories/linux-arm64-%E9%B2%B2%E9%B9%8F/"},{"name":"Go","slug":"Go","permalink":"https://www.yanwq.com/categories/Go/"},{"name":"Linux","slug":"Linux","permalink":"https://www.yanwq.com/categories/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://www.yanwq.com/categories/Docker/"},{"name":"Windows","slug":"Windows","permalink":"https://www.yanwq.com/categories/Windows/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.yanwq.com/categories/Ubuntu/"},{"name":"Proto","slug":"Proto","permalink":"https://www.yanwq.com/categories/Proto/"},{"name":"DB","slug":"DB","permalink":"https://www.yanwq.com/categories/DB/"}],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://www.yanwq.com/tags/ffmpeg/"},{"name":"达梦数据库","slug":"达梦数据库","permalink":"https://www.yanwq.com/tags/%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"gorm","slug":"gorm","permalink":"https://www.yanwq.com/tags/gorm/"},{"name":"docker","slug":"docker","permalink":"https://www.yanwq.com/tags/docker/"},{"name":"arm64","slug":"arm64","permalink":"https://www.yanwq.com/tags/arm64/"},{"name":"sqlite","slug":"sqlite","permalink":"https://www.yanwq.com/tags/sqlite/"},{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://www.yanwq.com/tags/rabbitMQ/"},{"name":"mysql","slug":"mysql","permalink":"https://www.yanwq.com/tags/mysql/"},{"name":"go-zero","slug":"go-zero","permalink":"https://www.yanwq.com/tags/go-zero/"},{"name":"consul","slug":"consul","permalink":"https://www.yanwq.com/tags/consul/"},{"name":"node","slug":"node","permalink":"https://www.yanwq.com/tags/node/"},{"name":"go","slug":"go","permalink":"https://www.yanwq.com/tags/go/"},{"name":"wsl2","slug":"wsl2","permalink":"https://www.yanwq.com/tags/wsl2/"},{"name":"es","slug":"es","permalink":"https://www.yanwq.com/tags/es/"},{"name":"grafana","slug":"grafana","permalink":"https://www.yanwq.com/tags/grafana/"},{"name":"oracle","slug":"oracle","permalink":"https://www.yanwq.com/tags/oracle/"},{"name":"cron","slug":"cron","permalink":"https://www.yanwq.com/tags/cron/"},{"name":"https","slug":"https","permalink":"https://www.yanwq.com/tags/https/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://www.yanwq.com/tags/ubuntu/"},{"name":"proto","slug":"proto","permalink":"https://www.yanwq.com/tags/proto/"},{"name":"db","slug":"db","permalink":"https://www.yanwq.com/tags/db/"}]}